{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "intro"
    ]
   },
   "source": [
    "# Grading process\n",
    "\n",
    "\n",
    "The submission notebook will be autovalidated with `papermill`. The exact command is the following:\n",
    "\n",
    "```bash\n",
    "papermill <notebook-name>.ipynb <notebook-name>-run.ipynb .ipynb -p TEST True\n",
    "```\n",
    "\n",
    "Papermill will inject new cell after each cell tagged as `parameters` (see `View > Cell toolbar > Tags`). Notebook will be executed from top to bottom in a linear order. `solutions.py` contains correct implementations used to validate your solutions.\n",
    "\n",
    "Please, **fill `STUDENT` variable with the name of submitting student**, so that we can collect the results automatically. Please, **do not change `TEST` variable** and `validation` cells. If you need to inject your own code for testing, wrap it into\n",
    "\n",
    "```python\n",
    "if not TEST:\n",
    "    ...\n",
    "```\n",
    "\n",
    "Different problems give different number of points. All problems in the basic section give 1 point, while all problems in intermediate section give 2 points.\n",
    "\n",
    "Each problem contains specific validation details. You need to fill each cell tagged `solution` with your code. Note, that solution function must self-contained, i.e. it must not use any state from the notebook itself.\n",
    "\n",
    "# Dataset\n",
    "\n",
    "All problems in the assignment use [electricity load dataset](https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014). Some functions/methods accept data itself, and in that case it's a Pandas dataframe as obtained by\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"LD2011_2014.txt\",\n",
    "                 parse_dates=[0],\n",
    "                 delimiter=\";\",\n",
    "                 decimal=\",\")\n",
    "df.rename({\"Unnamed: 0\": \"timestamp\"}, axis=1, inplace=True)\n",
    "```\n",
    "\n",
    "In contrast, whenever a function/method accepts a filename, it's the filename of **unzipped** data file (i.e. `LD2011_2014.txt`). When testing, do not rely on any specific location of the dataset, as validation environment will most certainly different from your local one. Hence, calls like\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"<your-local-directory>/LD2011_2014.txt\")\n",
    "```\n",
    "\n",
    "will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:04.111972Z",
     "start_time": "2019-10-30T22:26:04.107385Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:04.372936Z",
     "start_time": "2019-10-30T22:26:04.364608Z"
    }
   },
   "outputs": [],
   "source": [
    "STUDENT = \"Noam Salomonski\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ASSIGNMENT = 1\n",
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:39:38.188583Z",
     "start_time": "2019-10-30T22:39:38.182534Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    import solutions\n",
    "    total_grade = 0\n",
    "    MAX_POINTS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 1. Resample the dataset (1 point)\n",
    "\n",
    "Resample the dataset to 1-hour resolution. Use `mean` as an aggregation function. Your function must output a dataframe, with the same structure as the original one (i.e. not indexed by datetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  MT_001  MT_002  MT_003  MT_004  MT_005  MT_006  MT_007  \\\n",
      "0 2011-01-01 00:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1 2011-01-01 00:30:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2 2011-01-01 00:45:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3 2011-01-01 01:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4 2011-01-01 01:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   MT_008  MT_009  ...  MT_361  MT_362  MT_363  MT_364  MT_365  MT_366  \\\n",
      "0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   MT_367  MT_368  MT_369  MT_370  \n",
      "0     0.0     0.0     0.0     0.0  \n",
      "1     0.0     0.0     0.0     0.0  \n",
      "2     0.0     0.0     0.0     0.0  \n",
      "3     0.0     0.0     0.0     0.0  \n",
      "4     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 371 columns]\n"
     ]
    }
   ],
   "source": [
    "if not TEST:\n",
    "    orig_df = pd.read_csv(\"LD2011_2014.txt\",\n",
    "                 parse_dates=[0],\n",
    "                 delimiter=\";\",\n",
    "                 decimal=\",\")\n",
    "    orig_df.rename({\"Unnamed: 0\": \"timestamp\"}, axis=1, inplace=True)\n",
    "    print(orig_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:07.100307Z",
     "start_time": "2019-10-30T22:26:07.092132Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def el_resample(df):\n",
    "    # your code goes here\n",
    "    #print(df.head())\n",
    "    #print(df.index)\n",
    "    #print(df[\"timestamp\"].dtype)\n",
    "    df.timestamp = pd.to_datetime(df.timestamp)    \n",
    "    df = df.set_index([\"timestamp\"])\n",
    "    df = df.resample(\"H\").mean()\n",
    "    df.reset_index(inplace=True)\n",
    "    #print(df.head())\n",
    "    #print(df.index)\n",
    "    return df\n",
    "\n",
    "if not TEST:\n",
    "    el_resample(orig_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:07.334174Z",
     "start_time": "2019-10-30T22:26:07.322103Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 1\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, el_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 2. Consumption peaks (1 point)\n",
    "\n",
    "For each household, calculate, which month in 2014 had the highest consumption. Your function must output series, indexed by household ID (e.g., `MT_XXX`), and containing month as an integer (`1-12`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.274476Z",
     "start_time": "2019-10-30T22:26:08.268426Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  MT_001  MT_002  MT_003  MT_004  MT_005  MT_006  MT_007  \\\n",
      "0 2011-01-01 00:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1 2011-01-01 01:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2 2011-01-01 02:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3 2011-01-01 03:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4 2011-01-01 04:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   MT_008  MT_009  ...  MT_361  MT_362  MT_363  MT_364  MT_365  MT_366  \\\n",
      "0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   MT_367  MT_368  MT_369  MT_370  \n",
      "0     0.0     0.0     0.0     0.0  \n",
      "1     0.0     0.0     0.0     0.0  \n",
      "2     0.0     0.0     0.0     0.0  \n",
      "3     0.0     0.0     0.0     0.0  \n",
      "4     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 371 columns]\n",
      "RangeIndex(start=0, stop=35065, step=1)\n",
      "                timestamp    MT_001     MT_002    MT_003      MT_004  \\\n",
      "26304 2014-01-01 00:00:00  2.538071  24.004267  0.434405  148.882114   \n",
      "26305 2014-01-01 01:00:00  2.855330  23.293030  0.000000  145.833333   \n",
      "26306 2014-01-01 02:00:00  2.855330  24.537696  0.000000  142.276423   \n",
      "26307 2014-01-01 03:00:00  2.855330  21.870555  0.000000  127.032520   \n",
      "26308 2014-01-01 04:00:00  2.538071  22.226174  0.000000  111.280488   \n",
      "\n",
      "          MT_005      MT_006    MT_007      MT_008     MT_009  ...  \\\n",
      "26304  75.609756  276.041667  6.642171  247.474747  51.136364  ...   \n",
      "26305  71.036585  233.630952  5.935557  250.000000  52.010490  ...   \n",
      "26306  64.939024  212.797619  5.511588  251.683502  52.884615  ...   \n",
      "26307  64.634146  179.315476  5.935557  207.912458  46.765734  ...   \n",
      "26308  57.621951  156.250000  4.946297  191.077441  41.958042  ...   \n",
      "\n",
      "           MT_361   MT_362       MT_363       MT_364     MT_365     MT_366  \\\n",
      "26304  100.285510  15475.0  1161.392405  1011.363636  17.275098   9.362200   \n",
      "26305   71.556031  14875.0   638.185654   909.090909  16.949153  11.410181   \n",
      "26306   68.522484  14850.0   573.839662   880.681818  17.926988  10.239906   \n",
      "26307   68.344040  14275.0   565.400844   857.954545  16.949153  10.239906   \n",
      "26308   68.879372  13400.0   558.016878   863.636364  17.601043   8.045641   \n",
      "\n",
      "           MT_367     MT_368      MT_369       MT_370  \n",
      "26304  237.489025  46.327212  724.706745  7351.351351  \n",
      "26305  227.831431  48.414023  680.901760  7027.027027  \n",
      "26306  199.736611  50.500835  664.406158  6689.189189  \n",
      "26307  183.713784  46.327212  700.696481  6351.351351  \n",
      "26308  186.128183  47.579299  678.519062  6837.837838  \n",
      "\n",
      "[5 rows x 371 columns]\n",
      "len = 8760\n",
      "Int64Index([26304, 26305, 26306, 26307, 26308, 26309, 26310, 26311, 26312,\n",
      "            26313,\n",
      "            ...\n",
      "            35054, 35055, 35056, 35057, 35058, 35059, 35060, 35061, 35062,\n",
      "            35063],\n",
      "           dtype='int64', length=8760)\n"
     ]
    }
   ],
   "source": [
    "def cons_peak(df):\n",
    "    print(df.head())\n",
    "    print(df.index)\n",
    "    df2014 = df[df[\"timestamp\"].dt.year == 2014]\n",
    "    print(df2014.head())\n",
    "    print(f\"len = {len(df2014)}\")\n",
    "    print(df2014.index)\n",
    "\n",
    "if not TEST:\n",
    "    df = el_resample(orig_df.copy())\n",
    "    cons_peak(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.554208Z",
     "start_time": "2019-10-30T22:26:08.542546Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 2\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, cons_peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 3. Find minimum (2 points)\n",
    "\n",
    "Consider the following scalar function:\n",
    "\n",
    "$$\n",
    "f(x) = ax^2 + bx + c\n",
    "$$\n",
    "\n",
    "Given $a,b,c$, find $x$, which minimizes $f(x)$, and minimum value of $f(x)$. Note this:\n",
    "\n",
    "- $a,b,c$ are fixed, and generated in such a way, that minimum always exists ($f(x)$ is convex),\n",
    "- $x$ is a scalar value, i.e. 0-dimensional tensor.\n",
    "\n",
    "For reference, see `generate_coef` function, which is used to generate coefficients. Note, that since optimization process is not completely deterministic, the output is considered correct, if it falls within `1e-3` of actual values.\n",
    "\n",
    "This problem must be solved as an optimization one using gradient descent.\n",
    "\n",
    "For that, use only PyTorch functionality, `SciPy` (or alike) optimization routines are not allowed, neither is direct calculation using coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coeffs():\n",
    "    a = torch.rand(size=()) * 10\n",
    "    b = -10 + torch.rand(size=()) * 10\n",
    "    c = -10 + torch.rand(size=()) * 10\n",
    "    return a, b, c\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return x.pow(2) * a + x * b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.950073Z",
     "start_time": "2019-10-30T22:26:08.944541Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def find_min(a, b, c):\n",
    "    # your code goes here\n",
    "    # return x_min, val_min\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.170219Z",
     "start_time": "2019-10-30T22:26:09.158251Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 3\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, find_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 4. PyTorch `Dataset` (3 points)\n",
    "\n",
    "Implement a `torch.utils.data.Dataset` sub-class for the electricity consumption data. Individual training instances must be week-long univarite series of hourly consumption (input, 168 values), followed by 24-hours long series of hourly consumption (output, 24 values) for a single household. Such a class can be used when training a consumption forecast model, which uses 7 days of historical consumption to forecast next 24 hours of consumption.\n",
    "\n",
    "`__getitem__(self, idx)` must return a tuple of 1D tensors, `in_data` and `out_data`. `in_data` contains 168 hours of consumption (hourly), starting from some `start_ts`, while `out_data` must contain 24 hourly consumption values starting from `start_ts + 168 hours` for some household. `start_ts` should be sampled randomly.\n",
    "\n",
    "Also, you need to implement a `get_mapping(self, idx)` method, which allows to calculate `(household, starting time) -> idx` correspondence.\n",
    "\n",
    "This class will be validated as the following:\n",
    "\n",
    "- dataset object is created with some random `samples`: `dataset = ElDataset(df, samples)` ,\n",
    "- validator fetches random `idx` (between `0` and `len(dataset)`) from the dataset:\n",
    "```python\n",
    "household, start_ts = dataset.get_mapping(idx)\n",
    "hist_data, future_data = dataset[idx]\n",
    "```\n",
    "- then, `hist_data` and `future_data` are compared with the data, obtained directly from `df` using `household, start_ts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.531869Z",
     "start_time": "2019-10-30T22:26:09.523705Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "class ElDataset(Dataset):\n",
    "    \"\"\"Electricity dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, samples):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: original electricity data (see HW intro for details).\n",
    "            samples (int): number of sample to take per household.\n",
    "        \"\"\"\n",
    "        self.raw_data = df.set_index(\"\")\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples * (self.raw_data.shape[1] - 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # your code goes here\n",
    "        # return hist_data, future_data\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_mapping(self, idx):\n",
    "        # your code goes here\n",
    "        # return household, start_ts\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.716713Z",
     "start_time": "2019-10-30T22:26:09.707934Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 4\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, ElDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:39:26.661611Z",
     "start_time": "2019-10-30T22:39:26.654545Z"
    }
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    print(f\"{STUDENT}: {total_grade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}