{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "intro"
    ]
   },
   "source": [
    "# Grading process\n",
    "\n",
    "\n",
    "The submission notebook will be autovalidated with `papermill`. The exact command is the following:\n",
    "\n",
    "```bash\n",
    "papermill <notebook-name>.ipynb <notebook-name>-run.ipynb .ipynb -p TEST True\n",
    "```\n",
    "\n",
    "Papermill will inject new cell after each cell tagged as `parameters` (see `View > Cell toolbar > Tags`). Notebook will be executed from top to bottom in a linear order. `solutions.py` contains correct implementations used to validate your solutions.\n",
    "\n",
    "Please, **fill `STUDENT` variable with the name of submitting student**, so that we can collect the results automatically. Please, **do not change `TEST` variable** and `validation` cells. If you need to inject your own code for testing, wrap it into\n",
    "\n",
    "```python\n",
    "if not TEST:\n",
    "    ...\n",
    "```\n",
    "\n",
    "Different problems give different number of points. All problems in the basic section give 1 point, while all problems in intermediate section give 2 points.\n",
    "\n",
    "Each problem contains specific validation details. You need to fill each cell tagged `solution` with your code. Note, that solution function must self-contained, i.e. it must not use any state from the notebook itself.\n",
    "\n",
    "# Dataset\n",
    "\n",
    "All problems in the assignment use [electricity load dataset](https://archive.ics.uci.edu/ml/datasets/ElectricityLoadDiagrams20112014). Some functions/methods accept data itself, and in that case it's a Pandas dataframe as obtained by\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"LD2011_2014.txt\",\n",
    "                 parse_dates=[0],\n",
    "                 delimiter=\";\",\n",
    "                 decimal=\",\")\n",
    "df.rename({\"Unnamed: 0\": \"timestamp\"}, axis=1, inplace=True)\n",
    "```\n",
    "\n",
    "In contrast, whenever a function/method accepts a filename, it's the filename of **unzipped** data file (i.e. `LD2011_2014.txt`). When testing, do not rely on any specific location of the dataset, as validation environment will most certainly different from your local one. Hence, calls like\n",
    "\n",
    "```python\n",
    "df = pd.read_csv(\"<your-local-directory>/LD2011_2014.txt\")\n",
    "```\n",
    "\n",
    "will fail."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:04.111972Z",
     "start_time": "2019-10-30T22:26:04.107385Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:04.372936Z",
     "start_time": "2019-10-30T22:26:04.364608Z"
    }
   },
   "outputs": [],
   "source": [
    "STUDENT = \"Noam Salomonski\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "ASSIGNMENT = 1\n",
    "TEST = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:39:38.188583Z",
     "start_time": "2019-10-30T22:39:38.182534Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    import solutions\n",
    "    total_grade = 0\n",
    "    MAX_POINTS = 12"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 1. Resample the dataset (1 point)\n",
    "\n",
    "Resample the dataset to 1-hour resolution. Use `mean` as an aggregation function. Your function must output a dataframe, with the same structure as the original one (i.e. not indexed by datetime)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "            timestamp  MT_001  MT_002  MT_003  MT_004  MT_005  MT_006  MT_007  \\\n",
      "0 2011-01-01 00:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1 2011-01-01 00:30:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2 2011-01-01 00:45:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3 2011-01-01 01:00:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4 2011-01-01 01:15:00     0.0     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   MT_008  MT_009  ...  MT_361  MT_362  MT_363  MT_364  MT_365  MT_366  \\\n",
      "0     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "1     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "2     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "3     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "4     0.0     0.0  ...     0.0     0.0     0.0     0.0     0.0     0.0   \n",
      "\n",
      "   MT_367  MT_368  MT_369  MT_370  \n",
      "0     0.0     0.0     0.0     0.0  \n",
      "1     0.0     0.0     0.0     0.0  \n",
      "2     0.0     0.0     0.0     0.0  \n",
      "3     0.0     0.0     0.0     0.0  \n",
      "4     0.0     0.0     0.0     0.0  \n",
      "\n",
      "[5 rows x 371 columns]\n"
     ]
    }
   ],
   "source": [
    "if not TEST:\n",
    "    orig_df = pd.read_csv(\"LD2011_2014.txt\",\n",
    "                 parse_dates=[0],\n",
    "                 delimiter=\";\",\n",
    "                 decimal=\",\")\n",
    "    orig_df.rename({\"Unnamed: 0\": \"timestamp\"}, axis=1, inplace=True)\n",
    "    print(orig_df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:07.100307Z",
     "start_time": "2019-10-30T22:26:07.092132Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "def el_resample(df):\n",
    "    # your code goes here\n",
    "    #print(df.head())\n",
    "    #print(df.index)\n",
    "    #print(df[\"timestamp\"].dtype)\n",
    "    df = df.resample('H',on='timestamp').mean().reset_index()\n",
    "    #print(df.head())\n",
    "    #print(df.index)\n",
    "    return df\n",
    "\n",
    "if not TEST:\n",
    "    el_resample(orig_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:07.334174Z",
     "start_time": "2019-10-30T22:26:07.322103Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 1\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, el_resample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 2. Consumption peaks (1 point)\n",
    "\n",
    "For each household, calculate, which month in 2014 had the highest consumption. Your function must output series, indexed by household ID (e.g., `MT_XXX`), and containing month as an integer (`1-12`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.274476Z",
     "start_time": "2019-10-30T22:26:08.268426Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    timestamp        MT_001\n",
      "0  2014-01-31   7220.812183\n",
      "1  2014-02-28   6106.598985\n",
      "2  2014-03-31   7111.675127\n",
      "3  2014-04-30   8361.675127\n",
      "4  2014-05-31  14086.294416\n",
      "5  2014-06-30   6431.472081\n",
      "6  2014-07-31   6771.573604\n",
      "7  2014-08-31  45539.340102\n",
      "8  2014-09-30  23722.081218\n",
      "9  2014-10-31   4842.639594\n",
      "10 2014-11-30   5705.583756\n",
      "11 2014-12-31   6298.223350\n"
     ]
    }
   ],
   "source": [
    "def cons_peak(df):\n",
    "    #print(df.head())\n",
    "    #print(df.index)\n",
    "    df = df[[\"timestamp\", \"MT_001\"]]\n",
    "    df2014 = df[df[\"timestamp\"].dt.year == 2014]\n",
    "    months2014 = df2014.resample('M',on='timestamp').sum().reset_index()\n",
    "    print(months2014)\n",
    "    #print(f\"len = {len(months2014)}\")\n",
    "    max_month = months2014.drop([\"timestamp\"], axis=1).idxmax(axis=0)\n",
    "    #print(\"max_month:\")\n",
    "    #print(max_month)\n",
    "    #max_month.hist(bins=12)\n",
    "    return max_month\n",
    "\n",
    "if not TEST:\n",
    "    cons_peak(orig_df.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.554208Z",
     "start_time": "2019-10-30T22:26:08.542546Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 2\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, cons_peak)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 3. Find minimum (2 points)\n",
    "\n",
    "Consider the following scalar function:\n",
    "\n",
    "$$\n",
    "f(x) = ax^2 + bx + c\n",
    "$$\n",
    "\n",
    "Given $a,b,c$, find $x$, which minimizes $f(x)$, and minimum value of $f(x)$. Note this:\n",
    "\n",
    "- $a,b,c$ are fixed, and generated in such a way, that minimum always exists ($f(x)$ is convex),\n",
    "- $x$ is a scalar value, i.e. 0-dimensional tensor.\n",
    "\n",
    "For reference, see `generate_coef` function, which is used to generate coefficients. Note, that since optimization process is not completely deterministic, the output is considered correct, if it falls within `1e-3` of actual values.\n",
    "\n",
    "This problem must be solved as an optimization one using gradient descent.\n",
    "\n",
    "For that, use only PyTorch functionality, `SciPy` (or alike) optimization routines are not allowed, neither is direct calculation using coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_coeffs():\n",
    "    a = torch.rand(size=()) * 10\n",
    "    b = -10 + torch.rand(size=()) * 10\n",
    "    c = -10 + torch.rand(size=()) * 10\n",
    "    return a, b, c\n",
    "\n",
    "def func(x, a, b, c):\n",
    "    return x.pow(2) * a + x * b + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:08.950073Z",
     "start_time": "2019-10-30T22:26:08.944541Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "a=9.480217933654785, b=-5.104648590087891, c=-8.543782234191895, x_min=0.2692262530326843, val_min=-9.230935096740723\n",
      "a=1.0213559865951538, b=-2.8860039710998535, c=-1.782938003540039, x_min=1.4128267765045166, val_min=-3.8216538429260254\n",
      "a=9.113144874572754, b=-1.289876937866211, c=-9.285054206848145, x_min=0.07077011466026306, val_min=-9.330696105957031\n",
      "a=8.226265907287598, b=-9.908597946166992, c=-3.079348564147949, x_min=0.6022534966468811, val_min=-6.063093185424805\n",
      "a=5.855877876281738, b=-2.362658977508545, c=-4.808957576751709, x_min=0.20173390209674835, val_min=-5.047271728515625\n",
      "a=1.9252395629882812, b=-4.318721294403076, c=-3.8202099800109863, x_min=1.1216046810150146, val_min=-6.242162227630615\n",
      "a=7.137353897094727, b=-6.6887993812561035, c=-6.638684272766113, x_min=0.4685768783092499, val_min=-8.205793380737305\n",
      "a=9.111205101013184, b=-2.037245750427246, c=-3.643044948577881, x_min=0.11179890483617783, val_min=-3.7569258213043213\n",
      "a=3.5427613258361816, b=-7.320067882537842, c=-5.829472541809082, x_min=1.033101201057434, val_min=-9.610660552978516\n",
      "a=1.0204428434371948, b=-9.551790237426758, c=-2.879140853881836, x_min=4.680206298828125, val_min=-25.231372833251953\n",
      "a=7.491270065307617, b=-1.4299945831298828, c=-2.513428211212158, x_min=0.09544404596090317, val_min=-2.5816705226898193\n",
      "a=7.688081741333008, b=-4.6654863357543945, c=-9.020947456359863, x_min=0.3034231960773468, val_min=-9.728755950927734\n",
      "a=5.184998035430908, b=-4.2506561279296875, c=-3.1237244606018066, x_min=0.40989935398101807, val_min=-3.9948954582214355\n",
      "a=0.8521658182144165, b=-5.822214126586914, c=-9.92939567565918, x_min=3.4161205291748047, val_min=-19.874107360839844\n",
      "a=5.451582908630371, b=-9.079026222229004, c=-7.381948471069336, x_min=0.8326960802078247, val_min=-11.16198444366455\n",
      "a=9.622112274169922, b=-5.950100421905518, c=-3.378253936767578, x_min=0.3091888129711151, val_min=-4.2981061935424805\n",
      "a=0.03881633281707764, b=-8.248895645141602, c=-5.838733196258545, x_min=106.21046447753906, val_min=-444.08380126953125\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\noam\\ydata_timeseries_course\\venv\\lib\\site-packages\\ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "ename": "AssertionError",
     "evalue": "\nArrays are not almost equal to 4 decimals\n\nMismatched elements: 1 / 1 (100%)\nMax absolute difference: 0.0450058\nMax relative difference: 0.00042374\n x: array(106.2555, dtype=float32)\n y: array(106.2105, dtype=float32)",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAssertionError\u001B[0m                            Traceback (most recent call last)",
      "\u001B[1;32m<ipython-input-85-27af62f256f7>\u001B[0m in \u001B[0;36m<module>\u001B[1;34m\u001B[0m\n\u001B[0;32m     26\u001B[0m         \u001B[0manalytic_solution_val\u001B[0m \u001B[1;33m=\u001B[0m \u001B[0mfunc\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0manalytic_solution_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0ma\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mb\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mc\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     27\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n\u001B[1;32m---> 28\u001B[1;33m         \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtesting\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0massert_almost_equal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0manalytic_solution_x\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mx_min\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecimal\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m     29\u001B[0m         \u001B[0mnp\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mtesting\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0massert_almost_equal\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0manalytic_solution_val\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mval_min\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mdetach\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m.\u001B[0m\u001B[0mnumpy\u001B[0m\u001B[1;33m(\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mdecimal\u001B[0m\u001B[1;33m=\u001B[0m\u001B[1;36m4\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m     30\u001B[0m \u001B[1;33m\u001B[0m\u001B[0m\n",
      "    \u001B[1;31m[... skipping hidden 2 frame]\u001B[0m\n",
      "\u001B[1;32mc:\\noam\\ydata_timeseries_course\\venv\\lib\\site-packages\\numpy\\testing\\_private\\utils.py\u001B[0m in \u001B[0;36massert_array_compare\u001B[1;34m(comparison, x, y, err_msg, verbose, header, precision, equal_nan, equal_inf)\u001B[0m\n\u001B[0;32m    840\u001B[0m                                 \u001B[0mverbose\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mverbose\u001B[0m\u001B[1;33m,\u001B[0m \u001B[0mheader\u001B[0m\u001B[1;33m=\u001B[0m\u001B[0mheader\u001B[0m\u001B[1;33m,\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    841\u001B[0m                                 names=('x', 'y'), precision=precision)\n\u001B[1;32m--> 842\u001B[1;33m             \u001B[1;32mraise\u001B[0m \u001B[0mAssertionError\u001B[0m\u001B[1;33m(\u001B[0m\u001B[0mmsg\u001B[0m\u001B[1;33m)\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0m\u001B[0;32m    843\u001B[0m     \u001B[1;32mexcept\u001B[0m \u001B[0mValueError\u001B[0m\u001B[1;33m:\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n\u001B[0;32m    844\u001B[0m         \u001B[1;32mimport\u001B[0m \u001B[0mtraceback\u001B[0m\u001B[1;33m\u001B[0m\u001B[1;33m\u001B[0m\u001B[0m\n",
      "\u001B[1;31mAssertionError\u001B[0m: \nArrays are not almost equal to 4 decimals\n\nMismatched elements: 1 / 1 (100%)\nMax absolute difference: 0.0450058\nMax relative difference: 0.00042374\n x: array(106.2555, dtype=float32)\n y: array(106.2105, dtype=float32)"
     ]
    }
   ],
   "source": [
    "def find_min(a, b, c):\n",
    "    param = torch.zeros(size=(), requires_grad=True)\n",
    "    value_function = lambda x :func(x, a, b, c)\n",
    "    loss_function = lambda val: val\n",
    "\n",
    "    optimizer = torch.optim.SGD([param], lr=0.01)\n",
    "    for _ in range(10000):\n",
    "        optimizer.zero_grad()\n",
    "        value = value_function(param)\n",
    "        loss = loss_function(value)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    x_min = param\n",
    "    val_min = value_function(x_min)\n",
    "\n",
    "    return x_min, val_min\n",
    "\n",
    "if not TEST:\n",
    "    for _ in range(10):\n",
    "        a, b, c = generate_coeffs()\n",
    "        x_min, val_min = find_min(a, b, c)\n",
    "        print(f\"a={a}, b={b}, c={c}, x_min={x_min}, val_min={val_min}\")\n",
    "\n",
    "        analytic_solution_x = torch.tensor(-b / (2*a))\n",
    "        analytic_solution_val = func(analytic_solution_x, a, b, c)\n",
    "\n",
    "        np.testing.assert_almost_equal(analytic_solution_x, x_min.detach().numpy(), decimal=4),\n",
    "        np.testing.assert_almost_equal(analytic_solution_val, val_min.detach().numpy(), decimal=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.170219Z",
     "start_time": "2019-10-30T22:26:09.158251Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 3\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, find_min)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "tags": [
     "problem"
    ]
   },
   "source": [
    "### 4. PyTorch `Dataset` (3 points)\n",
    "\n",
    "Implement a `torch.utils.data.Dataset` sub-class for the electricity consumption data. Individual training instances must be week-long univarite series of hourly consumption (input, 168 values), followed by 24-hours long series of hourly consumption (output, 24 values) for a single household. Such a class can be used when training a consumption forecast model, which uses 7 days of historical consumption to forecast next 24 hours of consumption.\n",
    "\n",
    "`__getitem__(self, idx)` must return a tuple of 1D tensors, `in_data` and `out_data`. `in_data` contains 168 hours of consumption (hourly), starting from some `start_ts`, while `out_data` must contain 24 hourly consumption values starting from `start_ts + 168 hours` for some household. `start_ts` should be sampled randomly.\n",
    "\n",
    "Also, you need to implement a `get_mapping(self, idx)` method, which allows to calculate `(household, starting time) -> idx` correspondence.\n",
    "\n",
    "This class will be validated as the following:\n",
    "\n",
    "- dataset object is created with some random `samples`: `dataset = ElDataset(df, samples)` ,\n",
    "- validator fetches random `idx` (between `0` and `len(dataset)`) from the dataset:\n",
    "```python\n",
    "household, start_ts = dataset.get_mapping(idx)\n",
    "hist_data, future_data = dataset[idx]\n",
    "```\n",
    "- then, `hist_data` and `future_data` are compared with the data, obtained directly from `df` using `household, start_ts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.531869Z",
     "start_time": "2019-10-30T22:26:09.523705Z"
    },
    "tags": [
     "solution"
    ]
   },
   "outputs": [],
   "source": [
    "class ElDataset(Dataset):\n",
    "    \"\"\"Electricity dataset.\"\"\"\n",
    "\n",
    "    def __init__(self, df, samples):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df: original electricity data (see HW intro for details).\n",
    "            samples (int): number of sample to take per household.\n",
    "        \"\"\"\n",
    "        self.raw_data = df.set_index(\"\")\n",
    "        self.samples = samples\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.samples * (self.raw_data.shape[1] - 1)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        # your code goes here\n",
    "        # return hist_data, future_data\n",
    "        raise NotImplementedError\n",
    "\n",
    "    def get_mapping(self, idx):\n",
    "        # your code goes here\n",
    "        # return household, start_ts\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:26:09.716713Z",
     "start_time": "2019-10-30T22:26:09.707934Z"
    },
    "tags": [
     "validation"
    ]
   },
   "outputs": [],
   "source": [
    "PROBLEM_ID = 4\n",
    "\n",
    "if TEST:\n",
    "    total_grade += solutions.check(STUDENT, PROBLEM_ID, ElDataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your grade"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-10-30T22:39:26.661611Z",
     "start_time": "2019-10-30T22:39:26.654545Z"
    }
   },
   "outputs": [],
   "source": [
    "if TEST:\n",
    "    print(f\"{STUDENT}: {total_grade}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "@webio": {
   "lastCommId": null,
   "lastKernelId": null
  },
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}